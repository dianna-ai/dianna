@misc{ranguelova_how_2022,
	type = {Medium},
	title = {How to find your {Artificial} {Intelligence} explainer},
	url = {https://blog.esciencecenter.nl/how-to-find-your-artificial-intelligence-explainer-dbb1ac608009},
	language = {English},
	author = {Ranguelova, Elena and Liu, Yang},
	month = mar,
	year = {2022},
}

@article{Feger2020InteractiveTF,
  title={Interactive Tools for Reproducible Science - Understanding, Supporting, and Motivating Reproducible Science Practices},
  author={Sebastian Stefan Feger},
  journal={ArXiv},
  year={2020},
  volume={abs/2012.02570}
}

@article {hey,
	Title = {Machine learning and big scientific data},
	Author = {Hey, Tony and Butler, Keith and Jackson, Sam and Thiyagalingam, Jeyarajan},
	DOI = {10.1098/rsta.2019.0054},
	Number = {2166},
	Volume = {378},
	Month = {March},
	Year = {2020},
	Journal = {Philosophical transactions. Series A, Mathematical, physical, and engineering sciences},
	ISSN = {1364-503X},
	Pages = {20190054},
	Abstract = {This paper reviews some of the challenges posed by the huge growth of experimental data generated by the new generation of large-scale experiments at UK national facilities at the Rutherford Appleton Laboratory (RAL) site at Harwell near Oxford. Such 'Big Scientific Data' comes from the Diamond Light Source and Electron Microscopy Facilities, the ISIS Neutron and Muon Facility and the UK's Central Laser Facility. Increasingly, scientists are now required to use advanced machine learning and other AI technologies both to automate parts of the data pipeline and to help find new scientific discoveries in the analysis of their data. For commercially important applications, such as object recognition, natural language processing and automatic translation, deep learning has made dramatic breakthroughs. Google's DeepMind has now used the deep learning technology to develop their AlphaFold tool to make predictions for protein folding. Remarkably, it has been able to achieve some spectacular results for this specific scientific problem. Can deep learning be similarly transformative for other scientific problems? After a brief review of some initial applications of machine learning at the RAL, we focus on challenges and opportunities for AI in advancing materials science. Finally, we discuss the importance of developing some realistic machine learning benchmarks using Big Scientific Data coming from several different scientific domains. We conclude with some initial examples of our 'scientific machine learning' benchmark suite and of the research challenges these benchmarks will enable. This article is part of a discussion meeting issue 'Numerical algorithms for high-performance computational science'.},
	URL = {https://europepmc.org/articles/PMC7015290},
}

@article{lundbergshap,
  author    = {Scott M. Lundberg and
               Su{-}In Lee},
  title     = {A unified approach to interpreting model predictions},
  journal   = {CoRR},
  volume    = {abs/1705.07874},
  year      = {2017},
  url       = {http://arxiv.org/abs/1705.07874},
  eprinttype = {arXiv},
  eprint    = {1705.07874},
  timestamp = {Fri, 26 Nov 2021 16:33:36 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/LundbergL17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{petsiukrise,
  author    = {Vitali Petsiuk and
               Abir Das and
               Kate Saenko},
  title     = {{RISE:} Randomized Input Sampling for Explanation of Black-box Models},
  journal   = {CoRR},
  volume    = {abs/1806.07421},
  year      = {2018},
  url       = {http://arxiv.org/abs/1806.07421},
  eprinttype = {arXiv},
  eprint    = {1806.07421},
  timestamp = {Mon, 13 Aug 2018 16:47:36 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1806-07421.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{ribeirolime,
  author    = {Marco T{\'{u}}lio Ribeiro and
               Sameer Singh and
               Carlos Guestrin},
  title     = {"Why Should {I} Trust You?": Explaining the Predictions of Any Classifier},
  journal   = {CoRR},
  volume    = {abs/1602.04938},
  year      = {2016},
  url       = {http://arxiv.org/abs/1602.04938},
  eprinttype = {arXiv},
  eprint    = {1602.04938},
  timestamp = {Mon, 13 Aug 2018 16:49:09 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/RibeiroSG16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{xuwei,
    author = {Xu, Wei},
    title = {Toward Human-Centered AI: A Perspective from Human-Computer Interaction},
    year = {2019},
    issue_date = {July-August 2019},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    volume = {26},
    number = {4},
    issn = {1072-5520},
    url = {https://doi.org/10.1145/3328485},
    doi = {10.1145/3328485},
    journal = {Interactions},
    month = {jun},
    pages = {42–46},
    numpages = {5}
}

@article{alshehrifatima,
    author={Alshehri, Fatima and Muhammad, Ghulam},
    journal={IEEE Access},
    title={A Comprehensive Survey of the Internet of Things (IoT) and AI-Based Smart Healthcare},
    year={2021},
    volume={9},
    pages={3660-3678},
    doi={10.1109/ACCESS.2020.3047960}
}

@article{kuzlumurat,
    author={Kuzlu, Murat and Cali, Umit and Sharma, Vinayak and Güler, Özgür},
    journal={IEEE Access},
    title={Gaining Insight Into Solar Photovoltaic Power Generation Forecasting Utilizing Explainable Artificial Intelligence Tools},
    year={2020},
    volume={8},
    pages={187814-187823},
    doi={10.1109/ACCESS.2020.3031477}
}

@article{toorajipourreza,
	title = {Artificial intelligence in supply chain management: A systematic literature review},
	volume = {122},
	issn = {0148-2963},
	url = {https://www.sciencedirect.com/science/article/pii/S014829632030583X},
	doi = {https://doi.org/10.1016/j.jbusres.2020.09.009},
    pages = {502--517},
	journaltitle = {Journal of Business Research},
	author = {Toorajipour, Reza and Sohrabpour, Vahid and Nazarpour, Ali and Oghazi, Pejvak and Fischl, Maria},
	date = {2021},
	keywords = {Artificial intelligence, Supply chain management, Systematic literature review},
}

@inproceedings{dosilovic,
	author={Došilović, Filip Karlo and Brčić, Mario and Hlupić, Nikica},
	booktitle={2018 41st International Convention on Information and Communication Technology, Electronics and Microelectronics (MIPRO)}, 
	title={Explainable artificial intelligence: A survey}, 
	year={2018},
	volume={},
	pages={0210-0215},
	doi={10.23919/MIPRO.2018.8400040}
}

@article{joylu,
    author={Lu, Joy and Lee, Dokyun and Kim, Tae Wan and Danks, David},
    journal={SSRN},
    title={Good Explanation for Algorithmic Transparency},
    year={2019},
    url={https://ssrn.com/abstract=3503603},
    doi={10.2139/ssrn.3503603}
}

@article{peterflatch,
  author    = {Kacper Sokol and Peter A. Flach},
  title     = {Explainability Fact Sheets: {A} Framework for Systematic Assessment of Explainable Approaches},
  journal   = {CoRR},
  volume    = {abs/1912.05100},
  year      = {2019},
  url       = {http://arxiv.org/abs/1912.05100},
  eprinttype = {arXiv},
  eprint    = {1912.05100}
}

@misc{bryancardenas,
  author       = {Bryan Cardenas Guevara and Damian Podareanu and Matthieu Laneuville},
  title        = {XAI in practice: medical case study using DIANNA},
  month        = feb,
  year         = 2022,
  publisher    = {Zenodo},
  doi          = {10.5281/zenodo.6303282},
  url          = {https://doi.org/10.5281/zenodo.6303282}
}

@misc{uozbulak_pytorch_vis_2021,
  author = {Utku Ozbulak},
  title = {PyTorch CNN Visualizations},
  year = {2019},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/utkuozbulak/pytorch-cnn-visualizations}},
  commit = {53561b601c895f7d7d5bcf5fbc935a87ff08979a}
}

@article{nori2019interpretml,
  title={InterpretML: A Unified Framework for Machine Learning Interpretability},
  author={Nori, Harsha and Jenkins, Samuel and Koch, Paul and Caruana, Rich},
  journal={arXiv preprint arXiv:1909.09223},
  year={2019}
}

@misc{tflucid,
  title = {Lucid},
  year = {2021},
  publisher = {GitHub},
  journal = {GitHub repository},
  url = {https://github.com/tensorflow/lucid}
}

@misc{jacobgilpytorchcam,
  title={PyTorch library for CAM methods},
  author={Jacob Gildenblat and contributors},
  year={2021},
  publisher={GitHub},
  howpublished={\url{https://github.com/jacobgil/pytorch-grad-cam}},
}

@inproceedings{yosinski-2015-ICML-DL-understanding-neural-networks,
  Author = {Jason Yosinski and Jeff Clune and Anh Nguyen and Thomas Fuchs and Hod Lipson},
  Booktitle = {Deep Learning Workshop, International Conference on Machine Learning (ICML)},
  Title = {Understanding Neural Networks Through Deep Visualization},
  Year = {2015}
}

@misc{kokhlikyan2020captum,
    title={Captum: A unified and generic model interpretability library for PyTorch},
    author={Narine Kokhlikyan and Vivek Miglani and Miguel Martin and Edward Wang and Bilal Alsallakh and Jonathan Reynolds and Alexander Melnikov and Natalia Kliushkina and Carlos Araya and Siqi Yan and Orion Reblitz-Richardson},
    year={2020},
    eprint={2009.07896},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@misc{eli5,
  author = {Korobov, Mikhail and Lopuhin, Konstantin and others},
  title={ELI5},
  publisher={GitHub},
  howpublished={\url{https://github.com/TeamHG-Memex/eli5}},
  year = 2022
}

@misc{onnx,
    author = {Bai, Junjie and Lu, Fang and Zhang, Ke and others},
    title = {ONNX: Open Neural Network Exchange},
    year = {2019},
    publisher = {GitHub},
    howpublished = {\url{https://github.com/onnx/onnx}},
    commit = {94d238d96e3fb3a7ba34f03c284b9ad3516163be}
}

@misc{awesomeai,
  author = {Wang, Yongjie and others},
  title={Awesome-explainable-AI},
  publisher={GitHub},
  howpublished={\url{https://github.com/wangyongjie-ntu/Awesome-explainable-AI#python-librariessort-in-alphabeta-order}},
  year = 2022,
  note = {Accessed: 2022-3-16}
}

@software{tf,
  author = {Abadi, Martín and Agarwal, Ashish and Barham, Paul and Brevdo, Eugene and Chen, Zhifeng and Citro, Craig and Corrado, Greg S. and Davis, Andy and Dean, Jeffrey and Devin, Matthieu and Ghemawat, Sanjay and Goodfellow, Ian and Harp, Andrew and Irving, Geoffrey and Isard, Michael and Jozefowicz, Rafal and Jia, Yangqing and Kaiser, Lukasz and Kudlur, Manjunath and Levenberg, Josh and Mané, Dan and Schuster, Mike and Monga, Rajat and Moore, Sherry and Murray, Derek and Olah, Chris and Shlens, Jonathon and Steiner, Benoit and Sutskever, Ilya and Talwar, Kunal and Tucker, Paul and Vanhoucke, Vincent and Vasudevan, Vijay and Viégas, Fernanda and Vinyals, Oriol and Warden, Pete and Wattenberg, Martin and Wicke, Martin and Yu, Yuan and Zheng, Xiaoqiang},
  doi = {10.5281/zenodo.4724125},
  license = {Apache-2.0},
  month = {11},
  title = {{TensorFlow, Large-scale machine learning on heterogeneous systems}},
  year = {2015}
}

@incollection{pytorch,
  title = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
  author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
  booktitle = {Advances in Neural Information Processing Systems 32},
  editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
  pages = {8024--8035},
  year = {2019},
  publisher = {Curran Associates, Inc.},
  url = {http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf}
}

@article{innvestigatenn,
  author  = {Maximilian Alber and Sebastian Lapuschkin and Philipp Seegerer and Miriam H{{\"a}}gele and Kristof T. Sch{{\"u}}tt and Gr{{\'e}}goire Montavon and Wojciech Samek and Klaus-Robert M{{\"u}}ller and Sven D{{\"a}}hne and Pieter-Jan Kindermans},
  title   = {iNNvestigate Neural Networks!},
  journal = {Journal of Machine Learning Research},
  year    = {2019},
  volume  = {20},
  number  = {93},
  pages   = {1-8},
  url     = {http://jmlr.org/papers/v20/18-540.html}
}

@article{jia2014caffe,
  Author = {Jia, Yangqing and Shelhamer, Evan and Donahue, Jeff and Karayev, Sergey and Long, Jonathan and Girshick, Ross and Guadarrama, Sergio and Darrell, Trevor},
  Journal = {arXiv preprint arXiv:1408.5093},
  Title = {Caffe: Convolutional Architecture for Fast Feature Embedding},
  Year = {2014}
}

@misc{mnistdataset,
  title={THE MNIST DATABASE of handwritten digits},
  author={LeCun, Yann and Cortes, Corinna and Burges, Christopher J.C.},
  howpublished={\url{http://yann.lecun.com/exdb/mnist/}},
  year={2010}
}

@dataset{oostrum_leon_2021_5012825,
  author       = {Oostrum, Leon and
                  Liu, Yang and
                  Meijer, Christiaan and
                  Ranguelova, Elena and
                  Bos, Patrick},
  title        = {Simple Geometric Shapes},
  month        = jul,
  year         = 2021,
  publisher    = {Zenodo},
  version      = {1.0},
  doi          = {10.5281/zenodo.5012825},
  url          = {https://doi.org/10.5281/zenodo.5012825}
}

@dataset{ranguelova_elena_2021_5061353,
  author       = {Ranguelova, Elena and
                  Meijer, Christiaan and
                  Oostrum, Leon and
                  Liu, Yang and
                  Bos, Patrick},
  title        = {LeafSnap30},
  month        = jul,
  year         = 2021,
  note         = {{This dataset will be used for demonstration 
                   purposes in the open-source Deep Insight and
                   Neural Network Analysis (DIANNA) project, whose
                   goal is to provide a library for explainable AI
                   methods for scientists. DIANNA is work in progress
                   at the time of publishing this dataset version
                   (July 2021): https://github.com/dianna-ai/}},
  publisher    = {Zenodo},
  version      = {v.1.0},
  doi          = {10.5281/zenodo.5061353},
  url          = {https://doi.org/10.5281/zenodo.5061353}
}

@InProceedings{leafsnap_eccv2012,
  author = {Neeraj Kumar and Peter N. Belhumeur and Arijit Biswas and David W. Jacobs and W. John Kress and Ida Lopez and João V. B. Soares},
  title = {Leafsnap: A Computer Vision System for Automatic Plant Species Identification},
  booktitle = {The 12th European Conference on Computer Vision (ECCV)},
  month = {October},
  year = {2012}
}

@inproceedings{socher-etal-2013-recursive,
    title = {Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank},
    author = {Socher, Richard and Perelygin, Alex and Wu, Jean and Chuang, Jason and Manning, Christopher D. and Ng, Andrew and Potts, Christopher},
    booktitle = {Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing},
    month = oct,
    year = {2013},
    address = {Seattle, Washington, USA},
    publisher = {Association for Computational Linguistics},
    url = {https://aclanthology.org/D13-1170},
    pages = {1631--1642},
}

@misc{turkishdrama,
  author = {Peter Verhaar},
  title = {Mediating Islam in the Digital Age},
  year = {2022},
  publisher = {University of Leiden},
  journal = {Digital Scholarship@Leiden},
  url = {https://www.digitalscholarshipleiden.nl/articles/mediating-islam-in-the-digital-age}
}

@article{chrupala18,
  author    = {Grzegorz Chrupala},
  title     = {Symbolic inductive bias for visually grounded learning of spoken language},
  journal   = {CoRR},
  volume    = {abs/1812.09244},
  year      = {2018},
  url       = {http://arxiv.org/abs/1812.09244},
  eprinttype = {arXiv},
  eprint    = {1812.09244},
  timestamp = {Wed, 02 Jan 2019 14:40:18 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1812-09244.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{chrupala17representations,
    title = "Representations of language in a model of visually grounded speech signal",
    author = "Chrupa{\l}a, Grzegorz  and
      Gelderloos, Lieke  and
      Alishahi, Afra",
    booktitle = "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2017",
    address = "Vancouver, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P17-1057",
    doi = "10.18653/v1/P17-1057",
    pages = "613--622",
    abstract = "We present a visually grounded model of speech perception which projects spoken utterances and images to a joint semantic space. We use a multi-layer recurrent highway network to model the temporal nature of spoken speech, and show that it learns to extract both form and meaning-based linguistic knowledge from the input signal. We carry out an in-depth analysis of the representations used by different components of the trained model and show that encoding of semantic aspects tends to become richer as we go up the hierarchy of layers, whereas encoding of form-related aspects of the language input tends to initially increase and then plateau or decrease.",
}

@article{alishahi+17,
  author    = {Afra Alishahi and
               Marie Barking and
               Grzegorz Chrupala},
  title     = {Encoding of phonology in a recurrent neural model of grounded speech},
  journal   = {CoRR},
  volume    = {abs/1706.03815},
  year      = {2017},
  url       = {http://arxiv.org/abs/1706.03815},
  eprinttype = {arXiv},
  eprint    = {1706.03815},
  timestamp = {Mon, 13 Aug 2018 16:46:47 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/AlishahiBC17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@inproceedings{chrupala+19,
  title = "On the difficulty of a distributional semantics of spoken language",
  abstract = "The bulk of research in the area of speech processing concerns itself with supervised approaches to transcribing spoken language into text. In the domain of unsupervised learning most work on speech has focused on discovering relatively low level constructs such as phoneme inventories or word-like units. This is in contrast to research on written language, where there is a large body of work on unsupervised induction of semantic representations of words and whole sentences and longer texts. In this study we examine the challenges of adapting these approaches from written to spoken language. We conjecture that unsupervised learning of spoken language semantics becomes possible if we abstract from the surface variability. We simulate this setting by using a dataset of utterances spoken by a realistic but uniform synthetic voice. We evaluate two simple unsupervised models which, to varying degrees of success, learn semantic representations of speech fragments. Finally we suggest possible routes toward transferring our methods to the domain of unrestricted natural speech. ",
  keywords = "cs.CL, cs.LG, cs.SD, eess.AS",
  author = "Grzegorz Chrupa{\l}a and Lieke Gelderloos and {\'A}kos K{\'a}d{\'a}r and Afra Alishahi",
  year = "2019",
  doi = "10.7275/extq-7546",
  language = "English",
  volume = "2",
  booktitle = "Proceedings of the Society for Computation in Linguistics",
  note = "Society for Computation in Linguistics ; Conference date: 03-01-2019",
  url = "https://blogs.umass.edu/scil/scil-2019/"
}

@article{chrupala2021,
  author    = {Grzegorz Chrupala},
  title     = {Visually grounded models of spoken language: {A} survey of datasets,
               architectures and evaluation techniques},
  journal   = {CoRR},
  volume    = {abs/2104.13225},
  year      = {2021},
  url       = {https://arxiv.org/abs/2104.13225},
  eprinttype = {arXiv},
  eprint    = {2104.13225},
  timestamp = {Tue, 04 May 2021 15:12:43 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2104-13225.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
