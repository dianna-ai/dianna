{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<img width=\"150\" alt=\"Logo_ER10\" src=\"https://user-images.githubusercontent.com/3244249/151994514-b584b984-a148-4ade-80ee-0f88b0aefa45.png\">\n",
    "\n",
    "### Model Interpretation for Pretrained Binary MNIST Model using KernelSHAP\n",
    "\n",
    "This notebook demonstrates how to apply KernelSHAP method on pretrained binary MNIST model using a hand-written digit image. It visualizes the relevance attributions for each pixel/super-pixel by displaying them on the image. <br>\n",
    "\n",
    "SHapley Additive exPlanations, in short, SHAP, is a model-agnostic explainable AI approach which is used to decrypt the black-box models through estimating the Shapley values.<br>\n",
    "\n",
    "KernelSHAP is a variant of SHAP. It is a method that uses the LIME framework to compute Shapley Values.<br>\n",
    "\n",
    "More details about this method can be found in the paper https://arxiv.org/abs/1705.07874."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore') # disable warnings relateds to versions of tf\n",
    "import numpy as np\n",
    "import dianna\n",
    "import onnx\n",
    "from onnx_tf.backend import prepare\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 1 - Loading the model and the dataset\n",
    "Loads pretrained binary MNIST model and the image to be explained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Load saved binary MNIST data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# load dataset\n",
    "data = np.load('./data/binary-mnist.npz')\n",
    "# load testing data and the related labels\n",
    "X_test = data['X_test'].astype(np.float32).reshape([-1, 28, 28, 1]) / 255\n",
    "y_test = data['y_test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Load the pretrained binary MNIST model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Load saved onnx model\n",
    "onnx_model_path = \"./models/mnist_model_tf.onnx\"\n",
    "onnx_model = onnx.load(onnx_model_path)\n",
    "# get the output node\n",
    "output_node = prepare(onnx_model, gen_tensor_dict=True).outputs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Print class and image of a single instance in the test data for preview."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: digit 0\n"
     ]
    },
    {
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x1e1b28c0eb0>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# class name\n",
    "class_name = ['digit 0', 'digit 1']\n",
    "# instance index\n",
    "i_instance = 1\n",
    "# select instance for testing\n",
    "test_sample = X_test[i_instance].copy().astype(np.float32)\n",
    "# model predictions with added batch axis to test sample\n",
    "predictions = prepare(onnx_model).run(test_sample[None, ...])[f'{output_node}']\n",
    "pred_class = class_name[np.argmax(predictions)]\n",
    "print(\"The predicted class is:\", pred_class)\n",
    "plt.imshow(X_test[i_instance][:,:,0], cmap='gray')  # 0 for channel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 2 - Compute Shapley values and visualize the relevance attributions\n",
    "Approximate Shapley values using KernelSHAP and visualize the relevance attributions on the image. <br>\n",
    "\n",
    "KernelSHAP approximate Shapley values in the LIME framework.\n",
    "The user need to specified the number of times to re-evaluate the model when explaining each prediction (`nsamples`). A binary mask need to be applied to the image to represent if an image region is hidden. It requires the background color for the masked image, which can be specified by `background`.<br>\n",
    "\n",
    "Performing KernelSHAP on each pixel is inefficient. It is always a good practice to segment the input image and perform computations on the obtained superpixels. This requires the user to specify some keyword arguments related to the segmentation, like the (approximate) number of labels in the segmented output image (`n_segments`), and width of Gaussian smoothing kernel for pre-processing for each dimension of the image (`sigma`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6063c70e03b84960bb8b72ca95d53062"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# use KernelSHAP to explain the network's predictions\n",
    "shap_values, segments_slic = dianna.explain_image(onnx_model_path, test_sample, labels=[1],\n",
    "                                                  method=\"KernelSHAP\", nsamples=1000,\n",
    "                                                  background=0, n_segments=200, sigma=0,\n",
    "                                                  axis_labels=('height','width','channels'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Define a function to fill each pixel with shap values based on the segmentation. <br>\n",
    "This function is used to make plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# fill each pixel with SHAP values \n",
    "def fill_segmentation(values, segmentation):\n",
    "    out = np.zeros(segmentation.shape)\n",
    "    for i in range(len(values)):\n",
    "        out[segmentation == i] = values[i]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Visualize Shapley scores on the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 720x288 with 4 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get the index of predictions\n",
    "top_preds = np.argsort(-predictions)\n",
    "inds = top_preds[0]\n",
    "# Visualize the explanations\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(10,4))\n",
    "axes[0].imshow(test_sample, cmap='gray')\n",
    "axes[0].axis('off')\n",
    "# get the range for color bar\n",
    "max_val = np.max([np.max(np.abs(shap_values[i][:,:-1])) for i in range(len(shap_values))])\n",
    "# plot the test image and the attributions on the image for each class\n",
    "for i in range(2):\n",
    "    m = fill_segmentation(shap_values[inds[i]][0], segments_slic)\n",
    "    axes[i+1].set_title(str(inds[i]))\n",
    "    axes[i+1].imshow(test_sample, alpha=0.15)\n",
    "    im = axes[i+1].imshow(m, vmin=-max_val, vmax=max_val, cmap='bwr')\n",
    "    #axes[i+1].axis('off')\n",
    "    axes[i+1].set_xticks([])\n",
    "    axes[i+1].set_yticks([])\n",
    "cb = fig.colorbar(im, ax=axes.ravel().tolist(), label=\"SHAP value\", orientation=\"horizontal\", aspect=60)\n",
    "cb.outline.set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 3 - Conclusions\n",
    "The Shapley scores are estimated using KernelSHAP for models used to categorize the binary MNIST. The example here shows that the KernelSHAP method evaluates the importance of each segmentation/super pixel to the classification and the results are reasonable compared to the human visual preception of the chosen testing hand-written digit image.\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7604e8ec5f09e490e10161e37a4725039efd3ab703d81b1b8a1e00d6741866c"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}