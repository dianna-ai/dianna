{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "african-verse",
   "metadata": {},
   "source": [
    "<img width=\"150\" alt=\"Logo_ER10\" src=\"https://user-images.githubusercontent.com/3244249/151994514-b584b984-a148-4ade-80ee-0f88b0aefa45.png\">\n",
    "\n",
    "### Interpreting a movie review sentiment model with RISE\n",
    "This notebook demonstrates the use of DIANNA with the RISE method on the [Stanford Sentiment Treebank dataset](https://nlp.stanford.edu/sentiment/index.html) which contains one-sentence movie reviews. See also [their paper](https://nlp.stanford.edu/~socherr/EMNLP2013_RNTN.pdf). A pre-trained neural network classifier is used, which identifies whether a movie review is positive or negative.\n",
    "\n",
    "RISE is short for Randomized Input Sampling for Explanation of Black-box Models. It estimates each word's relevance to the model's decision empirically by probing the model with randomly masked versions of the input image and obtaining the corresponding outputs.  \n",
    "\n",
    "More details about this method can be found in the paper https://arxiv.org/abs/1806.07421.\n",
    "\n",
    "*NOTE*: This tutorial is still work-in-progress, the final results need to be improved by tweaking the RISE parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5cf6f82-c1c7-4814-ae0f-5a1c0b8578f6",
   "metadata": {},
   "source": [
    "#### 1. Imports and paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34b556d8-5337-44dc-8efe-14d1dff6f011",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import spacy\n",
    "from torchtext.vocab import Vectors\n",
    "from scipy.special import expit as sigmoid\n",
    "\n",
    "import dianna\n",
    "from dianna import visualization\n",
    "from dianna import utils\n",
    "from dianna.utils.tokenizers import SpacyTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c616916c-78ef-48d0-a744-b25b37b62a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = Path('models', 'movie_review_model.onnx')\n",
    "word_vector_path = Path('data', 'movie_reviews_word_vectors.txt')\n",
    "labels = (\"negative\", \"positive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad4f5b1-6097-4ef3-98c4-78432ad640b0",
   "metadata": {},
   "source": [
    "#### 2. Loading the model\n",
    "\n",
    "The classifier is stored in ONNX format. It accepts numerical tokens as input, and outputs a score between 0 and 1, where 0 means the review is negative and 1 that it is positive.  \n",
    "Here we define a class to run the model, which accepts a sentence (i.e. string) as input instead and returns two classes: negative and positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486540bd-2676-4dfa-bbe8-ee8aa289acd3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ensure the tokenizer for english is available\n",
    "spacy.cli.download('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "555842c5-3f82-4f63-93bb-696645d4b447",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieReviewsModelRunner:\n",
    "    def __init__(self, model, word_vectors, max_filter_size):\n",
    "        self.run_model = utils.get_function(model)\n",
    "        self.vocab = Vectors(word_vectors, cache=os.path.dirname(word_vectors))\n",
    "        self.max_filter_size = max_filter_size\n",
    "        \n",
    "        self.tokenizer = SpacyTokenizer(name='en_core_web_sm')\n",
    "\n",
    "    def __call__(self, sentences):\n",
    "        # ensure the input has a batch axis\n",
    "        if isinstance(sentences, str):\n",
    "            sentences = [sentences]\n",
    "\n",
    "        output = []\n",
    "        for sentence in sentences:\n",
    "            # tokenize and pad to minimum length\n",
    "            tokens = self.tokenizer.tokenize(sentence)\n",
    "            if len(tokens) < self.max_filter_size:\n",
    "                tokens += ['<pad>'] * (self.max_filter_size - len(tokens))\n",
    "            \n",
    "            # numericalize the tokens\n",
    "            tokens_numerical = [self.vocab.stoi[token] if token in self.vocab.stoi else self.vocab.stoi['<unk>']\n",
    "                                for token in tokens]\n",
    "\n",
    "            # run the model, applying a sigmoid because the model outputs logits, remove any remaining batch axis\n",
    "            pred = float(sigmoid(self.run_model([tokens_numerical])))\n",
    "            output.append(pred)\n",
    "\n",
    "        # output two classes\n",
    "        positivity = np.array(output)\n",
    "        negativity = 1 - positivity\n",
    "        return np.transpose([negativity, positivity])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "443e8a99-6fa3-4a73-9311-2fbe0251c2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model runner. max_filter_size is a property of the model\n",
    "model_runner = MovieReviewsModelRunner(model_path, word_vector_path, max_filter_size=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ccb569-a2e9-41b3-a732-f6c31a929a90",
   "metadata": {},
   "source": [
    "#### 3. Applying RISE with DIANNA\n",
    "The simplest way to run DIANNA on text data is with `dianna.explain_text`. The arguments are:\n",
    "* The function that runs the model (a path to a model in ONNX format is also accepted)\n",
    "* The text we want to explain\n",
    "* The name of the explainable-AI method we want to use, here RISE\n",
    "* The numerical indices of the classes we want an explanation for\n",
    "\n",
    "`dianna.explain_text` returns a list of tuples. Each tuple contains a word, its location in the input text, and its relevance for the selected output class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fc6ebcb-2328-4c06-ae67-c5590032eb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "review = \"A delectable and intriguing thriller filled with surprises\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c0bfd7d-df1d-4981-b714-496bc16b9347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rise parameter p_keep was automatically determined at 0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explaining: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:17<00:00,  1.72s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('A', 0, 0.7158780014514923),\n",
       " ('delectable', 1, 0.913871341049671),\n",
       " ('and', 2, 0.6892129376530648),\n",
       " ('intriguing', 3, 1.0620161551237106),\n",
       " ('thriller', 4, 0.840078490972519),\n",
       " ('filled', 5, 0.6051010835170746),\n",
       " ('with', 6, 0.6926153092086315),\n",
       " ('surprises', 7, 0.6697717276215553)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# An explanation is returned for each label, but we ask for just one label so the output is a list of length one.\n",
    "explanation_relevances =  dianna.explain_text(model_runner, review, model_runner.tokenizer, 'RISE',\n",
    "                                              labels=[labels.index('positive')])[0]\n",
    "explanation_relevances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e177746-3654-4518-9c1c-b7047f922273",
   "metadata": {},
   "source": [
    "#### 4. Visualization\n",
    "DIANNA includes a visualization package, capable of highlighting each word of a text based on their relevance scores. The visualization is in HTML format.\n",
    "In this visualization, words in favour of the selected class are highlighted in red. Words against the selected class are not present in this example, otherwise they would be highlighted in blue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0136005d-a22f-43a0-80da-4ec1f283f870",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html><body><span style=\"background:rgba(255, 0, 0, 0.54)\">A</span> <span style=\"background:rgba(255, 0, 0, 0.69)\">delectable</span> <span style=\"background:rgba(255, 0, 0, 0.52)\">and</span> <span style=\"background:rgba(255, 0, 0, 0.80)\">intriguing</span> <span style=\"background:rgba(255, 0, 0, 0.63)\">thriller</span> <span style=\"background:rgba(255, 0, 0, 0.46)\">filled</span> <span style=\"background:rgba(255, 0, 0, 0.52)\">with</span> <span style=\"background:rgba(255, 0, 0, 0.50)\">surprises</span></body></html>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualization.highlight_text(explanation_relevances, model_runner.tokenizer.tokenize(review))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3325a0-c091-4212-938d-7ef771304b22",
   "metadata": {},
   "source": [
    "The visualization is not very clear, as all words seem relevant for the review's outcome. From the numerical values above, we see that indeed all words contribute positively according to RISE, with \"intriguing\" as the most important word with a score of 0.94."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
