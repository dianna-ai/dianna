{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<img width=\"150\" alt=\"Logo_ER10\" src=\"https://user-images.githubusercontent.com/3244249/151994514-b584b984-a148-4ade-80ee-0f88b0aefa45.png\">\n",
    "\n",
    "### Model Interpretation for Pretrained Binary MNIST Model using KernelSHAP\n",
    "\n",
    "This notebook demonstrates how to apply KernelSHAP method on pretrained binary MNIST model using a hand-written digit image. It visualizes the relevance attributions for each pixel/super-pixel by displaying them on the image. <br>\n",
    "\n",
    "SHapley Additive exPlanations, in short, SHAP, is a model-agnostic explainable AI approach which is used to decrypt the black-box models through estimating the Shapley values.<br>\n",
    "\n",
    "KernelSHAP is a variant of SHAP. It is a method that uses the LIME framework to compute Shapley Values.<br>\n",
    "\n",
    "More details about this method can be found in the paper https://arxiv.org/abs/1705.07874."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Colab Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "running_in_colab = 'google.colab' in str(get_ipython())\n",
    "if running_in_colab:\n",
    "  # install dianna\n",
    "  !python3 -m pip install dianna[notebooks]\n",
    "  \n",
    "  # download data used in this demo\n",
    "  import os \n",
    "  base_url = 'https://raw.githubusercontent.com/dianna-ai/dianna/main/dianna/'\n",
    "  paths_to_download = ['./data/binary-mnist.npz', './models/mnist_model_tf.onnx']\n",
    "  for path in paths_to_download:\n",
    "      !wget {base_url + path} -P {os.path.dirname(path)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore') # disable warnings relateds to versions of tf\n",
    "import numpy as np\n",
    "import dianna\n",
    "import onnx\n",
    "from onnx_tf.backend import prepare\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 1 - Loading the model and the dataset\n",
    "Loads pretrained binary MNIST model and the image to be explained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Load saved binary MNIST data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# load dataset\n",
    "data = np.load(Path('..','..','..','dianna','data', 'binary-mnist.npz'))\n",
    "# load testing data and the related labels\n",
    "X_test = data['X_test'].astype(np.float32).reshape([-1, 28, 28, 1]) / 255\n",
    "y_test = data['y_test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Load the pretrained binary MNIST model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 11:29:59.327587: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-05-09 11:29:59.327685: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "# Load saved onnx model\n",
    "onnx_model_path = Path('..','..','..','dianna','models', 'mnist_model_tf.onnx')\n",
    "onnx_model = onnx.load(onnx_model_path)\n",
    "# get the output node\n",
    "output_node = prepare(onnx_model, gen_tensor_dict=True).outputs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Print class and image of a single instance in the test data for preview."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 11:30:01.721074: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2023-05-09 11:30:01.721134: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: digit 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x29a603400>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# class name\n",
    "class_name = ['digit 0', 'digit 1']\n",
    "# instance index\n",
    "i_instance = 1\n",
    "# select instance for testing\n",
    "test_sample = X_test[i_instance].copy().astype(np.float32)\n",
    "# model predictions with added batch axis to test sample\n",
    "predictions = prepare(onnx_model).run(test_sample[None, ...])[f'{output_node}']\n",
    "pred_class = class_name[np.argmax(predictions)]\n",
    "print(\"The predicted class is:\", pred_class)\n",
    "plt.imshow(X_test[i_instance][:,:,0], cmap='gray')  # 0 for channel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 2 - Compute Shapley values and visualize the relevance attributions\n",
    "Approximate Shapley values using KernelSHAP and visualize the relevance attributions on the image. <br>\n",
    "\n",
    "KernelSHAP approximate Shapley values in the LIME framework.\n",
    "The user need to specified the number of times to re-evaluate the model when explaining each prediction (`nsamples`). A binary mask need to be applied to the image to represent if an image region is hidden. It requires the background color for the masked image, which can be specified by `background`.<br>\n",
    "\n",
    "Performing KernelSHAP on each pixel is inefficient. It is always a good practice to segment the input image and perform computations on the obtained superpixels. This requires the user to specify some keyword arguments related to the segmentation, like the (approximate) number of labels in the segmented output image (`n_segments`), and width of Gaussian smoothing kernel for pre-processing for each dimension of the image (`sigma`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 11:30:03.734986: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]2023-05-09 11:30:03.991305: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-05-09 11:30:04.602026: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.80s/it]\n"
     ]
    }
   ],
   "source": [
    "# use KernelSHAP to explain the network's predictions\n",
    "shap_values, segments_slic = dianna.explain_image(onnx_model_path, test_sample, labels=[1],\n",
    "                                                  method=\"KernelSHAP\", nsamples=1000,\n",
    "                                                  background=0, n_segments=200, sigma=0,\n",
    "                                                  axis_labels=('height','width','channels'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Define a function to fill each pixel with shap values based on the segmentation. <br>\n",
    "This function is used to make plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# fill each pixel with SHAP values \n",
    "def fill_segmentation(values, segmentation):\n",
    "    out = np.zeros(segmentation.shape)\n",
    "    for i in range(len(values)):\n",
    "        out[segmentation == i] = values[i]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Visualize Shapley scores on the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get the index of predictions\n",
    "top_preds = np.argsort(-predictions)\n",
    "inds = top_preds[0]\n",
    "# Visualize the explanations\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(10,4))\n",
    "axes[0].imshow(test_sample, cmap='gray')\n",
    "axes[0].axis('off')\n",
    "# get the range for color bar\n",
    "max_val = np.max([np.max(np.abs(shap_values[i][:,:-1])) for i in range(len(shap_values))])\n",
    "# plot the test image and the attributions on the image for each class\n",
    "for i in range(2):\n",
    "    m = fill_segmentation(shap_values[inds[i]][0], segments_slic)\n",
    "    axes[i+1].set_title(str(inds[i]))\n",
    "    axes[i+1].imshow(test_sample, alpha=0.15)\n",
    "    im = axes[i+1].imshow(m, vmin=-max_val, vmax=max_val, cmap='bwr')\n",
    "    #axes[i+1].axis('off')\n",
    "    axes[i+1].set_xticks([])\n",
    "    axes[i+1].set_yticks([])\n",
    "cb = fig.colorbar(im, ax=axes.ravel().tolist(), label=\"SHAP value\", orientation=\"horizontal\", aspect=60)\n",
    "cb.outline.set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 3 - Conclusions\n",
    "The Shapley scores are estimated using KernelSHAP for models used to categorize the binary MNIST. The example here shows that the KernelSHAP method evaluates the importance of each segmentation/super pixel to the classification and the results are reasonable compared to the human visual preception of the chosen testing hand-written digit image.\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7604e8ec5f09e490e10161e37a4725039efd3ab703d81b1b8a1e00d6741866c"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
