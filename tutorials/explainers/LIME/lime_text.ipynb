{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "african-verse",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<img width=\"150\" alt=\"Logo_ER10\" src=\"https://user-images.githubusercontent.com/3244249/151994514-b584b984-a148-4ade-80ee-0f88b0aefa45.png\">\n",
    "\n",
    "### Interpreting a movie review sentiment model with LIME\n",
    "This notebook demonstrates the use of DIANNA with the LIME method on the [Stanford Sentiment Treebank dataset](https://nlp.stanford.edu/sentiment/index.html) which contains one-sentence movie reviews. See also [their paper](https://nlp.stanford.edu/~socherr/EMNLP2013_RNTN.pdf). A pre-trained neural network classifier is used, which identifies whether a movie review is positive or negative.\n",
    "\n",
    "LIME (Local Interpretable Model-agnostic Explanations) is an explainable-AI method that aims to create an interpretable model that locally represents the classifier. For more details see the [LIME paper](https://arxiv.org/abs/1602.04938)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6d17b0",
   "metadata": {},
   "source": [
    "#### Colab Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "471630ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "running_in_colab = 'google.colab' in str(get_ipython())\n",
    "if running_in_colab:\n",
    "  # install dianna\n",
    "  !python3 -m pip install dianna[notebooks]\n",
    "  \n",
    "  # download data used in this demo\n",
    "  import os \n",
    "  base_url = 'https://raw.githubusercontent.com/dianna-ai/dianna/main/tutorials/'\n",
    "  paths_to_download = ['data/movie_reviews_word_vectors.txt', 'models/movie_review_model.onnx']\n",
    "  for path in paths_to_download:\n",
    "      !wget {base_url + path} -P {os.path.dirname(path)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5cf6f82-c1c7-4814-ae0f-5a1c0b8578f6",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 1. Imports and paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34b556d8-5337-44dc-8efe-14d1dff6f011",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-21 16:35:38.025595: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-21 16:35:39.445116: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import spacy\n",
    "from torchtext.vocab import Vectors\n",
    "from scipy.special import expit as sigmoid\n",
    "from pathlib import Path\n",
    "\n",
    "import dianna\n",
    "from dianna import visualization\n",
    "from dianna import utils\n",
    "from dianna.utils.tokenizers import SpacyTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c616916c-78ef-48d0-a744-b25b37b62a3f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_path = Path('models', 'movie_review_model.onnx')\n",
    "word_vector_path = Path('data', 'movie_reviews_word_vectors.txt')\n",
    "labels = (\"negative\", \"positive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad4f5b1-6097-4ef3-98c4-78432ad640b0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 2. Loading the model\n",
    "\n",
    "The classifier is stored in ONNX format. It accepts numerical tokens as input, and outputs a score between 0 and 1, where 0 means the review is negative and 1 that it is positive.  \n",
    "Here we define a class to run the model, which accepts a sentence (i.e. string) as input instead and returns two classes: negative and positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "486540bd-2676-4dfa-bbe8-ee8aa289acd3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.5.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.5.0/en_core_web_sm-3.5.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /home/yangliu/venv/dianna/lib/python3.10/site-packages (from en-core-web-sm==3.5.0) (3.5.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /home/yangliu/venv/dianna/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/yangliu/venv/dianna/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/yangliu/venv/dianna/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.9)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/yangliu/venv/dianna/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.7)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/yangliu/venv/dianna/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.8)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /home/yangliu/venv/dianna/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.10)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /home/yangliu/venv/dianna/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /home/yangliu/venv/dianna/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.4.6)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/yangliu/venv/dianna/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.8)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /home/yangliu/venv/dianna/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.9.0)\n",
      "Requirement already satisfied: pathy>=0.10.0 in /home/yangliu/venv/dianna/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.10.2)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /home/yangliu/venv/dianna/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (6.3.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/yangliu/venv/dianna/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.65.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/yangliu/venv/dianna/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.23.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/yangliu/venv/dianna/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /home/yangliu/venv/dianna/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.10.10)\n",
      "Requirement already satisfied: jinja2 in /home/yangliu/venv/dianna/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /home/yangliu/venv/dianna/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (65.5.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/yangliu/venv/dianna/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (23.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/yangliu/venv/dianna/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.3.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /home/yangliu/venv/dianna/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.6.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/yangliu/venv/dianna/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/yangliu/venv/dianna/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/yangliu/venv/dianna/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/yangliu/venv/dianna/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2023.5.7)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /home/yangliu/venv/dianna/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /home/yangliu/venv/dianna/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.1.0)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/yangliu/venv/dianna/lib/python3.10/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/yangliu/venv/dianna/lib/python3.10/site-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.1.3)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# ensure the tokenizer for english is available\n",
    "spacy.cli.download('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "555842c5-3f82-4f63-93bb-696645d4b447",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class MovieReviewsModelRunner:\n",
    "    def __init__(self, model, word_vectors, max_filter_size):\n",
    "        self.run_model = utils.get_function(str(model))\n",
    "        self.vocab = Vectors(word_vectors, cache=os.path.dirname(word_vectors))\n",
    "        self.max_filter_size = max_filter_size\n",
    "        \n",
    "        self.tokenizer =  SpacyTokenizer(name='en_core_web_sm')\n",
    "\n",
    "    def __call__(self, sentences):\n",
    "        # ensure the input has a batch axis\n",
    "        if isinstance(sentences, str):\n",
    "            sentences = [sentences]\n",
    "\n",
    "        tokenized_sentences = []\n",
    "        for sentence in sentences:\n",
    "            # tokenize and pad to minimum length\n",
    "            tokens = self.tokenizer.tokenize(sentence.lower())\n",
    "            if len(tokens) < self.max_filter_size:\n",
    "                tokens += ['<pad>'] * (self.max_filter_size - len(tokens))\n",
    "            \n",
    "            # numericalize the tokens\n",
    "            tokens_numerical = [self.vocab.stoi[token] if token in self.vocab.stoi else self.vocab.stoi['<unk>']\n",
    "                                for token in tokens]\n",
    "            tokenized_sentences.append(tokens_numerical)\n",
    "            \n",
    "        # run the model, applying a sigmoid because the model outputs logits\n",
    "        logits = self.run_model(tokenized_sentences)\n",
    "        pred = np.apply_along_axis(sigmoid, 1, logits)\n",
    "        \n",
    "        # output two classes\n",
    "        positivity = pred[:, 0]\n",
    "        negativity = 1 - positivity\n",
    "        return np.transpose([negativity, positivity])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "443e8a99-6fa3-4a73-9311-2fbe0251c2b1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# define model runner. max_filter_size is a property of the model\n",
    "model_runner = MovieReviewsModelRunner(model_path, word_vector_path, max_filter_size=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ccb569-a2e9-41b3-a732-f6c31a929a90",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 3. Applying LIME with DIANNA\n",
    "The simplest way to run DIANNA on text data is with `dianna.explain_text`. The arguments are:\n",
    "* The function that runs the model (a path to a model in ONNX format is also accepted)\n",
    "* The text we want to explain\n",
    "* The name of the explainable-AI method we want to use, here LIME\n",
    "* The numerical index of the class we want an explanation for\n",
    "\n",
    "`dianna.explain_text` returns a list of tuples. Each tuple contains a word, its location in the input text, and its importance for the selected output class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fc6ebcb-2328-4c06-ae67-c5590032eb69",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "review = \"A delectable and intriguing thriller filled with surprises\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c0bfd7d-df1d-4981-b714-496bc16b9347",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('intriguing', 3, 0.1542104335885818),\n",
       " ('delectable', 1, 0.06238614802957715),\n",
       " ('thriller', 4, 0.060795676689237396),\n",
       " ('A', 0, 0.021020044831623636),\n",
       " ('and', 2, 0.018838286814627653),\n",
       " ('filled', 5, -0.013061654174455994),\n",
       " ('with', 6, 0.012917500384050744),\n",
       " ('surprises', 7, 0.006322756636057935)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We're getting the explanation for the 'positive' class only,\n",
    "# but dianna supports explaining for multiple labels in one go.\n",
    "# It therefore always outputs a list of saliency maps. We want\n",
    "# the first and only saliency map from this list here.\n",
    "explanation_relevance = dianna.explain_text(model_runner, review, model_runner.tokenizer,\n",
    "                                            'LIME', labels=[labels.index('positive')])[0]\n",
    "explanation_relevance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e177746-3654-4518-9c1c-b7047f922273",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 4. Visualization\n",
    "DIANNA includes a visualization package, capable of highlighting the relevance of each word in the text for a chosen class. The visualization is in HTML format.\n",
    "Words in favour of the selected class are highlighted in red, while words against the selected class - in blue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0136005d-a22f-43a0-80da-4ec1f283f870",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<mark style=\"background-color: hsl(0, 100%, 94%, 0.8); line-height:1.75\">A</mark> <mark style=\"background-color: hsl(0, 100%, 80%, 0.8); line-height:1.75\">delectable</mark> <mark style=\"background-color: hsl(0, 100%, 94%, 0.8); line-height:1.75\">and</mark> <mark style=\"background-color: hsl(0, 100%, 50%, 0.8); line-height:1.75\">intriguing</mark> <mark style=\"background-color: hsl(0, 100%, 81%, 0.8); line-height:1.75\">thriller</mark> <mark style=\"background-color: hsl(240, 100%, 96%, 0.8); line-height:1.75\">filled</mark> <mark style=\"background-color: hsl(0, 100%, 96%, 0.8); line-height:1.75\">with</mark> <mark style=\"background-color: hsl(0, 100%, 98%, 0.8); line-height:1.75\">surprises</mark>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualization.highlight_text(explanation_relevance, model_runner.tokenizer.tokenize(review))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3325a0-c091-4212-938d-7ef771304b22",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The most important word for this review being classified as positive is \"intriguing\", followed by \"delectable\" and \"thriller\".\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
