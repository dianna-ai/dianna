{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "african-verse",
   "metadata": {},
   "source": [
    "## Interpreting a movie review sentiment model with LIME\n",
    "This notebook demonstrates the use of DIANNA with the LIME method on the [Stanford Sentiment Treebank dataset](https://nlp.stanford.edu/sentiment/index.html) which contains one-sentence movie reviews. See also [their paper](https://nlp.stanford.edu/~socherr/EMNLP2013_RNTN.pdf). A pre-trained neural network classifier is used, which identifies whether a movie review is positive or negative.\n",
    "\n",
    "LIME (Local Interpretable Model-agnostic Explanations) is an explainable-AI method that aims to create an interpretable model that locally represents the classifier. For more details see the [LIME paper](https://arxiv.org/abs/1602.04938)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5cf6f82-c1c7-4814-ae0f-5a1c0b8578f6",
   "metadata": {},
   "source": [
    "## 1. Imports and paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34b556d8-5337-44dc-8efe-14d1dff6f011",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import spacy\n",
    "from torchtext.data import get_tokenizer\n",
    "from torchtext.vocab import Vectors\n",
    "from scipy.special import expit as sigmoid\n",
    "\n",
    "import dianna\n",
    "from dianna import visualization\n",
    "from dianna import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c616916c-78ef-48d0-a744-b25b37b62a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'models/movie_review_model.onnx'\n",
    "word_vector_path = 'data/movie_reviews_word_vectors.txt'\n",
    "labels = (\"negative\", \"positive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad4f5b1-6097-4ef3-98c4-78432ad640b0",
   "metadata": {},
   "source": [
    "## 2. Loading the model\n",
    "\n",
    "The classifier is stored in ONNX format. It accepts numerical tokens as input, and outputs a score between 0 and 1, where 0 means the review is negative and 1 that it is positive.  \n",
    "Here we define a class to run the model, which accepts a sentence (i.e. string) as input instead and returns two classes: negative and positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486540bd-2676-4dfa-bbe8-ee8aa289acd3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ensure the tokenizer for english is available\n",
    "spacy.cli.download('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "555842c5-3f82-4f63-93bb-696645d4b447",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieReviewsModelRunner:\n",
    "    def __init__(self, model, word_vectors, max_filter_size):\n",
    "        self.run_model = utils.get_function(model)\n",
    "        self.vocab = Vectors(word_vectors, cache=os.path.dirname(word_vectors))\n",
    "        self.max_filter_size = max_filter_size\n",
    "        \n",
    "        self.tokenizer = get_tokenizer('spacy', 'en_core_web_sm')\n",
    "\n",
    "    def __call__(self, sentences):\n",
    "        # ensure the input has a batch axis\n",
    "        if isinstance(sentences, str):\n",
    "            sentences = [sentences]\n",
    "\n",
    "        tokenized_sentences = []\n",
    "        for sentence in sentences:\n",
    "            # tokenize and pad to minimum length\n",
    "            tokens = self.tokenizer(sentence)\n",
    "            if len(tokens) < self.max_filter_size:\n",
    "                tokens += ['<pad>'] * (self.max_filter_size - len(tokens))\n",
    "            \n",
    "            # numericalize the tokens\n",
    "            tokens_numerical = [self.vocab.stoi[token] if token in self.vocab.stoi else self.vocab.stoi['<unk>']\n",
    "                                for token in tokens]\n",
    "            tokenized_sentences.append(tokens_numerical)\n",
    "            \n",
    "        # run the model, applying a sigmoid because the model outputs logits\n",
    "        logits = self.run_model(tokenized_sentences)\n",
    "        pred = np.apply_along_axis(sigmoid, 1, logits)\n",
    "        \n",
    "        # output two classes\n",
    "        positivity = pred[:, 0]\n",
    "        negativity = 1 - positivity\n",
    "        return np.transpose([negativity, positivity])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "443e8a99-6fa3-4a73-9311-2fbe0251c2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model runner. max_filter_size is a property of the model\n",
    "model_runner = MovieReviewsModelRunner(model_path, word_vector_path, max_filter_size=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ccb569-a2e9-41b3-a732-f6c31a929a90",
   "metadata": {},
   "source": [
    "## 3. Applying LIME with DIANNA\n",
    "The simplest way to run DIANNA on text data is with `dianna.explain_text`. The arguments are:\n",
    "* The function that runs the model (a path to a model in ONNX format is also accepted)\n",
    "* The text we want to explain\n",
    "* The name of the explainable-AI method we want to use, here LIME\n",
    "* The numerical index of the class we want an explanation for\n",
    "\n",
    "`dianna.explain_text` returns a list of tuples. Each tuple contains a word, its location in the input text, and its importance for the selected output class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fc6ebcb-2328-4c06-ae67-c5590032eb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "review = \"A delectable and intriguing thriller filled with surprises\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c0bfd7d-df1d-4981-b714-496bc16b9347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('intriguing', 17, 0.17620261485039476),\n",
       " ('thriller', 28, 0.06872602847808185),\n",
       " ('delectable', 2, 0.06412120408567741),\n",
       " ('and', 13, 0.01826288634362681),\n",
       " ('with', 44, 0.015241920918278223),\n",
       " ('filled', 37, -0.010657806189826112),\n",
       " ('surprises', 49, 0.005177270693044006),\n",
       " ('A', 0, 0.004610194166739205)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# An explanation is returned for each label, but we ask for just one label so the output is a list of length one.\n",
    "explanation_relevance = dianna.explain_text(model_runner, review, 'LIME', label=labels.index('positive'))[0]\n",
    "explanation_relevance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e177746-3654-4518-9c1c-b7047f922273",
   "metadata": {},
   "source": [
    "### 4. Visualization\n",
    "DIANNA includes a visualization package, capable of highlighting the relevance of each word in the text for a chosen class. The visualization is in HTML format.\n",
    "Words in favour of the selected class are highlighted in red, while words against the selected class - in blue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0136005d-a22f-43a0-80da-4ec1f283f870",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html><body><span style=\"background:rgba(255, 0, 0, 0.02)\">A</span> <span style=\"background:rgba(255, 0, 0, 0.29)\">delectable</span> <span style=\"background:rgba(255, 0, 0, 0.08)\">and</span> <span style=\"background:rgba(255, 0, 0, 0.80)\">intriguing</span> <span style=\"background:rgba(255, 0, 0, 0.31)\">thriller</span> <span style=\"background:rgba(0, 0, 255, 0.048389)\">filled</span> <span style=\"background:rgba(255, 0, 0, 0.07)\">with</span> <span style=\"background:rgba(255, 0, 0, 0.02)\">surprises</span></body></html>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualization.highlight_text(explanation_relevance, review)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3325a0-c091-4212-938d-7ef771304b22",
   "metadata": {},
   "source": [
    "The most important word for this review being classified as positive is \"intriguing\", followed by \"delectable\" and \"thriller\"."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
