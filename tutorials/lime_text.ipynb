{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "african-verse",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<img width=\"150\" alt=\"Logo_ER10\" src=\"https://user-images.githubusercontent.com/3244249/151994514-b584b984-a148-4ade-80ee-0f88b0aefa45.png\">\n",
    "\n",
    "### Interpreting a movie review sentiment model with LIME\n",
    "This notebook demonstrates the use of DIANNA with the LIME method on the [Stanford Sentiment Treebank dataset](https://nlp.stanford.edu/sentiment/index.html) which contains one-sentence movie reviews. See also [their paper](https://nlp.stanford.edu/~socherr/EMNLP2013_RNTN.pdf). A pre-trained neural network classifier is used, which identifies whether a movie review is positive or negative.\n",
    "\n",
    "LIME (Local Interpretable Model-agnostic Explanations) is an explainable-AI method that aims to create an interpretable model that locally represents the classifier. For more details see the [LIME paper](https://arxiv.org/abs/1602.04938)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5cf6f82-c1c7-4814-ae0f-5a1c0b8578f6",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 1. Imports and paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34b556d8-5337-44dc-8efe-14d1dff6f011",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import spacy\n",
    "from torchtext.vocab import Vectors\n",
    "from scipy.special import expit as sigmoid\n",
    "from pathlib import Path\n",
    "\n",
    "import dianna\n",
    "from dianna import visualization\n",
    "from dianna import utils\n",
    "from dianna.utils.tokenizers import SpacyTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c616916c-78ef-48d0-a744-b25b37b62a3f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_path = Path('models', 'movie_review_model.onnx')\n",
    "word_vector_path = Path('data', 'movie_reviews_word_vectors.txt')\n",
    "labels = (\"negative\", \"positive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad4f5b1-6097-4ef3-98c4-78432ad640b0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 2. Loading the model\n",
    "\n",
    "The classifier is stored in ONNX format. It accepts numerical tokens as input, and outputs a score between 0 and 1, where 0 means the review is negative and 1 that it is positive.  \n",
    "Here we define a class to run the model, which accepts a sentence (i.e. string) as input instead and returns two classes: negative and positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "486540bd-2676-4dfa-bbe8-ee8aa289acd3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "# ensure the tokenizer for english is available\n",
    "spacy.cli.download('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "555842c5-3f82-4f63-93bb-696645d4b447",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class MovieReviewsModelRunner:\n",
    "    def __init__(self, model, word_vectors, max_filter_size):\n",
    "        self.run_model = utils.get_function(str(model))\n",
    "        self.vocab = Vectors(word_vectors, cache=os.path.dirname(word_vectors))\n",
    "        self.max_filter_size = max_filter_size\n",
    "        \n",
    "        self.tokenizer =  SpacyTokenizer(name='en_core_web_sm')\n",
    "\n",
    "    def __call__(self, sentences):\n",
    "        # ensure the input has a batch axis\n",
    "        if isinstance(sentences, str):\n",
    "            sentences = [sentences]\n",
    "\n",
    "        tokenized_sentences = []\n",
    "        for sentence in sentences:\n",
    "            # tokenize and pad to minimum length\n",
    "            tokens = self.tokenizer.tokenize(sentence.lower())\n",
    "            if len(tokens) < self.max_filter_size:\n",
    "                tokens += ['<pad>'] * (self.max_filter_size - len(tokens))\n",
    "            \n",
    "            # numericalize the tokens\n",
    "            tokens_numerical = [self.vocab.stoi[token] if token in self.vocab.stoi else self.vocab.stoi['<unk>']\n",
    "                                for token in tokens]\n",
    "            tokenized_sentences.append(tokens_numerical)\n",
    "            \n",
    "        # run the model, applying a sigmoid because the model outputs logits\n",
    "        logits = self.run_model(tokenized_sentences)\n",
    "        pred = np.apply_along_axis(sigmoid, 1, logits)\n",
    "        \n",
    "        # output two classes\n",
    "        positivity = pred[:, 0]\n",
    "        negativity = 1 - positivity\n",
    "        return np.transpose([negativity, positivity])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "443e8a99-6fa3-4a73-9311-2fbe0251c2b1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# define model runner. max_filter_size is a property of the model\n",
    "model_runner = MovieReviewsModelRunner(model_path, word_vector_path, max_filter_size=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ccb569-a2e9-41b3-a732-f6c31a929a90",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 3. Applying LIME with DIANNA\n",
    "The simplest way to run DIANNA on text data is with `dianna.explain_text`. The arguments are:\n",
    "* The function that runs the model (a path to a model in ONNX format is also accepted)\n",
    "* The text we want to explain\n",
    "* The name of the explainable-AI method we want to use, here LIME\n",
    "* The numerical index of the class we want an explanation for\n",
    "\n",
    "`dianna.explain_text` returns a list of tuples. Each tuple contains a word, its location in the input text, and its importance for the selected output class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fc6ebcb-2328-4c06-ae67-c5590032eb69",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "review = \"A delectable and intriguing thriller filled with surprises\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c0bfd7d-df1d-4981-b714-496bc16b9347",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('intriguing', 3, 0.15676576731098502),\n",
       " ('thriller', 4, 0.06416006115415027),\n",
       " ('delectable', 1, 0.06281683308649923),\n",
       " ('A', 0, 0.021482701114620962),\n",
       " ('and', 2, 0.018633385524976835),\n",
       " ('with', 6, 0.010678822730754416),\n",
       " ('filled', 5, -0.01067822597152755),\n",
       " ('surprises', 7, 0.0047279251801326146)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We're getting the explanation for the 'positive' class only, but dianna supports explaining for multiple labels in one\n",
    "# go. It therefore always outputs a list of saliency maps. We want the first and only saliency map from this list here.\n",
    "explanation_relevance = dianna.explain_text(model_runner, review, model_runner.tokenizer, 'LIME', labels=[labels.index('positive')])[0]\n",
    "explanation_relevance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e177746-3654-4518-9c1c-b7047f922273",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 4. Visualization\n",
    "DIANNA includes a visualization package, capable of highlighting the relevance of each word in the text for a chosen class. The visualization is in HTML format.\n",
    "Words in favour of the selected class are highlighted in red, while words against the selected class - in blue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0136005d-a22f-43a0-80da-4ec1f283f870",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html><body><span style=\"background:rgba(255, 0, 0, 0.11)\">A</span> <span style=\"background:rgba(255, 0, 0, 0.32)\">delectable</span> <span style=\"background:rgba(255, 0, 0, 0.10)\">and</span> <span style=\"background:rgba(255, 0, 0, 0.80)\">intriguing</span> <span style=\"background:rgba(255, 0, 0, 0.33)\">thriller</span> <span style=\"background:rgba(0, 0, 255, 0.054493)\">filled</span> <span style=\"background:rgba(255, 0, 0, 0.05)\">with</span> <span style=\"background:rgba(255, 0, 0, 0.02)\">surprises</span></body></html>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualization.highlight_text(explanation_relevance, model_runner.tokenizer.tokenize(review))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3325a0-c091-4212-938d-7ef771304b22",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The most important word for this review being classified as positive is \"intriguing\", followed by \"delectable\" and \"thriller\".\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
