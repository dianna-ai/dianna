{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img width=\"150\" alt=\"Logo_ER10\" src=\"https://user-images.githubusercontent.com/3244249/151994514-b584b984-a148-4ade-80ee-0f88b0aefa45.png\">\n",
    "\n",
    "## Keras to ONNX conversion\n",
    "This notebook shows how to convert your trained Keras model to ONNX, the generic format supported by DIANNA. <br>\n",
    "\n",
    "The conversion is complete with the tf2onnx Python package, which supports both the SavedModel format and the older HDF5 (.h5 or .keras) format. It can convert multi-backend keras as well as tf.keras models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-12 14:12:39.037240: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-12 14:12:39.100024: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-12 14:12:39.100061: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-12 14:12:39.102844: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-12 14:12:39.115682: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-12 14:12:39.116951: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-12 14:12:40.469062: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import onnx\n",
    "import onnxruntime as ort\n",
    "# In addition to these imports, this notebook\n",
    "# depends on tf2onnx. It is used from the command line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download and initialize built-in model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.applications.mobilenet.MobileNet(weights='imagenet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate model on some random input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 983ms/step\n"
     ]
    }
   ],
   "source": [
    "input_shape = [1] + model.inputs[0].shape[1:]  # input shape without a 1 for batch size, instead of None\n",
    "input_data = np.random.normal(size=input_shape).astype(np.float32)\n",
    "pred = model.predict(input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save keras model to SavedModel format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: mysavedmodel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: mysavedmodel/assets\n"
     ]
    }
   ],
   "source": [
    "savedmodel_dir = 'mysavedmodel'\n",
    "tf.saved_model.save(model, savedmodel_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert to ONNX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-12 14:13:15.345213: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-12 14:13:15.345304: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-12 14:13:15.346390: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-12 14:13:16.833234: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/usr/lib/python3.10/runpy.py:126: RuntimeWarning: 'tf2onnx.convert' found in sys.modules after import of package 'tf2onnx', but prior to execution of 'tf2onnx.convert'; this may result in unpredictable behaviour\n",
      "  warn(RuntimeWarning(msg))\n",
      "2023-12-12 14:13:23,137 - INFO - Signatures found in model: [serving_default].\n",
      "2023-12-12 14:13:23,138 - INFO - Output names: ['predictions']\n",
      "2023-12-12 14:13:23,138 - WARNING - Could not search for non-variable resources. Concrete function internal representation may have changed.\n",
      "2023-12-12 14:13:24,308 - INFO - Using tensorflow=2.15.0, onnx=1.14.0, tf2onnx=1.15.1/37820d\n",
      "2023-12-12 14:13:24,308 - INFO - Using opset <onnx, 15>\n",
      "2023-12-12 14:13:24,488 - INFO - Computed 0 values for constant folding\n",
      "2023-12-12 14:13:24,924 - INFO - Optimizing ONNX model\n",
      "2023-12-12 14:13:26,281 - INFO - After optimization: BatchNormalization -27 (27->0), Cast -2 (2->0), Concat -1 (1->0), Const -163 (223->60), GlobalAveragePool +1 (0->1), Identity -2 (2->0), ReduceMean -1 (1->0), Reshape -13 (14->1), Shape -1 (1->0), Slice -1 (1->0), Squeeze -1 (1->0), Transpose -122 (123->1), Unsqueeze -2 (2->0)\n",
      "2023-12-12 14:13:26,307 - INFO - \n",
      "2023-12-12 14:13:26,307 - INFO - Successfully converted TensorFlow model mysavedmodel to ONNX\n",
      "2023-12-12 14:13:26,307 - INFO - Model inputs: ['input_1']\n",
      "2023-12-12 14:13:26,307 - INFO - Model outputs: ['predictions']\n",
      "2023-12-12 14:13:26,307 - INFO - ONNX model is saved at mysavedmodel.onnx\n"
     ]
    }
   ],
   "source": [
    "onnx_savedmodel = 'mysavedmodel.onnx'\n",
    "!python -m tf2onnx.convert --saved-model {savedmodel_dir} --output {onnx_savedmodel} --signature_def serving_default --tag serve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate ONNX models and compare to keras model output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# verify the ONNX model is valid\n",
    "onnx_model = onnx.load(Path(onnx_savedmodel))\n",
    "onnx.checker.check_model(onnx_model)\n",
    "\n",
    "# get ONNX predictions\n",
    "sess = ort.InferenceSession(onnx_savedmodel)\n",
    "input_name = sess.get_inputs()[0].name\n",
    "output_name = sess.get_outputs()[0].name\n",
    "\n",
    "onnx_input = {input_name: input_data}\n",
    "pred_onnx = sess.run([output_name], onnx_input)[0]\n",
    "\n",
    "print(np.allclose(pred_onnx, pred, atol=1e-5))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7604e8ec5f09e490e10161e37a4725039efd3ab703d81b1b8a1e00d6741866c"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
