{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img width=\"150\" alt=\"Logo_ER10\" src=\"https://user-images.githubusercontent.com/3244249/151994514-b584b984-a148-4ade-80ee-0f88b0aefa45.png\">\n",
    "\n",
    "## Keras to ONNX conversion\n",
    "This notebook shows how to convert your trained Keras model to ONNX, the generic format supported by DIANNA. <br>\n",
    "\n",
    "The conversion is complete with the tf2onnx Python package, which supports both the SavedModel format and the older HDF5 (.h5 or .keras) format. It can convert multi-backend keras as well as tf.keras models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import onnx\n",
    "import onnxruntime as ort\n",
    "# In addition to these imports, this notebook\n",
    "# depends on tf2onnx. It is used from the command line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download and initialize built-in model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = keras.applications.resnet50.ResNet50(include_top=True, weights='imagenet')\n",
    "model = keras.applications.resnet50.ResNet50(weights='imagenet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate model on some random input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = [1] + model.inputs[0].shape[1:]  # input shape without a 1 for batch size, instead of None\n",
    "input_data = np.random.normal(size=input_shape).astype(np.float32)\n",
    "pred = model.predict(input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save keras model to SavedModel format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ChristiaanMeijer\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: resnet_savedmodel\\assets\n"
     ]
    }
   ],
   "source": [
    "savedmodel_dir = 'resnet_savedmodel'\n",
    "# tf.saved_model.save(model, savedmodel_dir)\n",
    "model.save(savedmodel_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert to ONNX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_savedmodel = 'resnet_savedmodel.onnx'\n",
    "x = !python -m tf2onnx.convert --saved-model {savedmodel_dir} --output {onnx_savedmodel} --signature_def serving_default --tag serve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "2022-03-09 17:22:36.115310: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n2022-03-09 17:22:36.115353: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\nC:\\Users\\ChristiaanMeijer\\anaconda3\\envs\\temp-dianna\\lib\\runpy.py:127: RuntimeWarning: 'tf2onnx.convert' found in sys.modules after import of package 'tf2onnx', but prior to execution of 'tf2onnx.convert'; this may result in unpredictable behaviour\n  warn(RuntimeWarning(msg))\n2022-03-09 17:22:39.052299: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'nvcuda.dll'; dlerror: nvcuda.dll not found\n2022-03-09 17:22:39.052320: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n2022-03-09 17:22:39.055889: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: ESLT0114\n2022-03-09 17:22:39.056012: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: ESLT0114\n2022-03-09 17:22:39.056273: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2022-03-09 17:22:45,051 - INFO - Signatures found in model: [serving_default].\n2022-03-09 17:22:45,053 - INFO - Output names: ['predictions']\n2022-03-09 17:22:45.073680: I tensorflow/core/grappler/devices.cc:69] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n2022-03-09 17:22:45.073837: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n2022-03-09 17:22:45.134801: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1144] Optimization results for grappler item: graph_to_optimize\n  function_optimizer: Graph size after: 1200 nodes (877), 1855 edges (1532), time = 35.424ms.\n  function_optimizer: function_optimizer did nothing. time = 0.823ms.\n\nWARNING:tensorflow:From C:\\Users\\ChristiaanMeijer\\anaconda3\\envs\\temp-dianna\\lib\\site-packages\\tf2onnx\\tf_loader.py:706: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse `tf.compat.v1.graph_util.extract_sub_graph`\n2022-03-09 17:22:47,902 - WARNING - From C:\\Users\\ChristiaanMeijer\\anaconda3\\envs\\temp-dianna\\lib\\site-packages\\tf2onnx\\tf_loader.py:706: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse `tf.compat.v1.graph_util.extract_sub_graph`\n2022-03-09 17:22:48.043042: I tensorflow/core/grappler/devices.cc:69] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n2022-03-09 17:22:48.043226: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n2022-03-09 17:22:49.149443: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1144] Optimization results for grappler item: graph_to_optimize\n  constant_folding: Graph size after: 560 nodes (-640), 1215 edges (-640), time = 745.965ms.\n  function_optimizer: function_optimizer did nothing. time = 11.382ms.\n  constant_folding: Graph size after: 560 nodes (0), 1215 edges (0), time = 115.357ms.\n  function_optimizer: function_optimizer did nothing. time = 8.512ms.\n\n2022-03-09 17:22:49,746 - INFO - Using tensorflow=2.5.0, onnx=1.11.0, tf2onnx=1.9.3/1190aa\n2022-03-09 17:22:49,746 - INFO - Using opset <onnx, 9>\n2022-03-09 17:22:55,843 - INFO - Computed 0 values for constant folding\n2022-03-09 17:22:59,736 - INFO - Optimizing ONNX model\n2022-03-09 17:23:03,792 - INFO - After optimization: Add -1 (18->17), BatchNormalization -53 (53->0), Const -162 (270->108), GlobalAveragePool +1 (0->1), Identity -57 (57->0), ReduceMean -1 (1->0), Squeeze +1 (0->1), Transpose -213 (214->1)\n2022-03-09 17:23:04,037 - INFO - \n2022-03-09 17:23:04,037 - INFO - Successfully converted TensorFlow model resnet_savedmodel to ONNX\n2022-03-09 17:23:04,037 - INFO - Model inputs: ['input_1']\n2022-03-09 17:23:04,038 - INFO - Model outputs: ['predictions']\n2022-03-09 17:23:04,038 - INFO - ONNX model is saved at resnet_savedmodel.onnx",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(x)\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(s)\n",
      "\u001b[1;31mException\u001b[0m: 2022-03-09 17:22:36.115310: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n2022-03-09 17:22:36.115353: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\nC:\\Users\\ChristiaanMeijer\\anaconda3\\envs\\temp-dianna\\lib\\runpy.py:127: RuntimeWarning: 'tf2onnx.convert' found in sys.modules after import of package 'tf2onnx', but prior to execution of 'tf2onnx.convert'; this may result in unpredictable behaviour\n  warn(RuntimeWarning(msg))\n2022-03-09 17:22:39.052299: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'nvcuda.dll'; dlerror: nvcuda.dll not found\n2022-03-09 17:22:39.052320: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n2022-03-09 17:22:39.055889: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: ESLT0114\n2022-03-09 17:22:39.056012: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: ESLT0114\n2022-03-09 17:22:39.056273: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2022-03-09 17:22:45,051 - INFO - Signatures found in model: [serving_default].\n2022-03-09 17:22:45,053 - INFO - Output names: ['predictions']\n2022-03-09 17:22:45.073680: I tensorflow/core/grappler/devices.cc:69] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n2022-03-09 17:22:45.073837: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n2022-03-09 17:22:45.134801: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1144] Optimization results for grappler item: graph_to_optimize\n  function_optimizer: Graph size after: 1200 nodes (877), 1855 edges (1532), time = 35.424ms.\n  function_optimizer: function_optimizer did nothing. time = 0.823ms.\n\nWARNING:tensorflow:From C:\\Users\\ChristiaanMeijer\\anaconda3\\envs\\temp-dianna\\lib\\site-packages\\tf2onnx\\tf_loader.py:706: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse `tf.compat.v1.graph_util.extract_sub_graph`\n2022-03-09 17:22:47,902 - WARNING - From C:\\Users\\ChristiaanMeijer\\anaconda3\\envs\\temp-dianna\\lib\\site-packages\\tf2onnx\\tf_loader.py:706: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse `tf.compat.v1.graph_util.extract_sub_graph`\n2022-03-09 17:22:48.043042: I tensorflow/core/grappler/devices.cc:69] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n2022-03-09 17:22:48.043226: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n2022-03-09 17:22:49.149443: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1144] Optimization results for grappler item: graph_to_optimize\n  constant_folding: Graph size after: 560 nodes (-640), 1215 edges (-640), time = 745.965ms.\n  function_optimizer: function_optimizer did nothing. time = 11.382ms.\n  constant_folding: Graph size after: 560 nodes (0), 1215 edges (0), time = 115.357ms.\n  function_optimizer: function_optimizer did nothing. time = 8.512ms.\n\n2022-03-09 17:22:49,746 - INFO - Using tensorflow=2.5.0, onnx=1.11.0, tf2onnx=1.9.3/1190aa\n2022-03-09 17:22:49,746 - INFO - Using opset <onnx, 9>\n2022-03-09 17:22:55,843 - INFO - Computed 0 values for constant folding\n2022-03-09 17:22:59,736 - INFO - Optimizing ONNX model\n2022-03-09 17:23:03,792 - INFO - After optimization: Add -1 (18->17), BatchNormalization -53 (53->0), Const -162 (270->108), GlobalAveragePool +1 (0->1), Identity -57 (57->0), ReduceMean -1 (1->0), Squeeze +1 (0->1), Transpose -213 (214->1)\n2022-03-09 17:23:04,037 - INFO - \n2022-03-09 17:23:04,037 - INFO - Successfully converted TensorFlow model resnet_savedmodel to ONNX\n2022-03-09 17:23:04,037 - INFO - Model inputs: ['input_1']\n2022-03-09 17:23:04,038 - INFO - Model outputs: ['predictions']\n2022-03-09 17:23:04,038 - INFO - ONNX model is saved at resnet_savedmodel.onnx"
     ]
    }
   ],
   "source": [
    "s = '\\n'.join(x)\n",
    "raise Exception(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate ONNX models and compare to keras model output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify the ONNX model is valid\n",
    "onnx_model = onnx.load(onnx_savedmodel)\n",
    "onnx.checker.check_model(onnx_model)\n",
    "\n",
    "# get ONNX predictions\n",
    "sess = ort.InferenceSession(onnx_savedmodel)\n",
    "input_name = sess.get_inputs()[0].name\n",
    "output_name = sess.get_outputs()[0].name\n",
    "\n",
    "onnx_input = {input_name: input_data}\n",
    "pred_onnx = sess.run([output_name], onnx_input)[0]\n",
    "\n",
    "print(np.allclose(pred_onnx, pred, atol=1e-5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7604e8ec5f09e490e10161e37a4725039efd3ab703d81b1b8a1e00d6741866c"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
